# MyPrjt

Softcomputing :

Interesting uses of neural networks, which have a history of only about 50 years, 
have only recently come to light (as part of the evolution of computing).
Single components (or neurons) acting in parallel make up neural networks.
The biological nervous system was a major source of inspiration for these aspects. 
Like in nature, the connections between the components have a significant impact on how the (neuron) network functions.
By changing the values of the connections (or weights) between the elements (neuron), we can train a neural network for a
particular job (such as the recognition of characters or numbers, for instance).
In general, neural network training is done so that there is a specified aim for each input that is given to the network.
The weights are adjusted until the output is consistent with the target (desired output) by comparing the network's response 
(or output obtained) and the target. The following learning algorithms will be the primary focus of this practical work :

- “Rosemblatt” perceptron algorithm 1958-1962.
   =>  Application:  The logical OR 
                     Recognition of parity of digits 
                     Number recognition
  
- Adaline algorithm (Delta rule) “Widrow-Hoff” 1960.
  =>  Application:   The logical OR 
                     Recognition of parity of digits 
                     Number recognition
  
- Backpropagation algorithm.
    =>  Application: Exclusive OR (XOR) 
                     Encoder (8-3-8)

 You can find more information and explanation of all those Algorithm and their code in the attached rapport.pdf file 
 (the file is in french but you can easily translate it good luck!! ) 
